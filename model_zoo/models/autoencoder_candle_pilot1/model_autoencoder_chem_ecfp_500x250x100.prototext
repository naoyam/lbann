trainer {
  num_parallel_readers: 1
}
model {
  ### Model description and network architecture taken from:
  ### https://lc.llnl.gov/bitbucket/projects/BIOM/repos/molresp/browse/tf_model.py?at=TensorFlow_chemClass
  ### This network description is anologous to AutoEncoder_Chem_ECFP
  data_layout: "model_parallel"
  mini_batch_size: 1024
  num_epochs:20

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    layer_term { layer: "mean_squared_error" }
  }

  ###################################################
  # Metrics
  ###################################################

  metric {
    layer_metric {
      name: "Pearson correlation"
      layer: "pearson_r"
    }
  }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    print {
      interval: 1
    }
  }
  callback {
    timer {
    }
  }

  ###################################################
  # start of layers
  ###################################################

  #######
  # INPUT
  #######
  layer {
    name: "input"
    children: "data dummy"
    data_layout: "data_parallel"
    input {}
  }
  layer {
    parents: "input"
    name: "data"
    data_layout: "data_parallel"
    split {}
  }
  layer {
    parents: "input"
    name: "dummy"
    data_layout: "data_parallel"
    dummy {}
  }

  #################
  # FULLY_CONNECTED encode1
  #################
  layer {
    parents: "data"
    name: "encode1"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 500
      has_bias: true
    }
  }

  ######
  # SELU selu1
  ######
  layer {
    parents: "encode1"
    name: "selu1"
    data_layout: "model_parallel"
    selu {
    }
  }

  #################
  # FULLY_CONNECTED encode2
  #################
  layer {
    parents: "selu1"
    name: "encode2"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 250
      has_bias: true
    }
  }

  #######
  # SELU selu2
  #######
  layer {
    parents: "encode2"
    name: "selu2"
    data_layout: "model_parallel"
    selu {
    }
  }

  #################
  # FULLY_CONNECTED encode3
  #################
  layer {
    parents: "selu2"
    name: "encode3"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 100
      has_bias: true
    }
  }

  #######
  # SELU selu3
  #######
  layer {
    parents: "encode3"
    name: "selu3"
    data_layout: "model_parallel"
    selu {
    }
  }


  #################
  # FULLY_CONNECTED decode3
  #################
  layer {
    parents: "selu3"
    name: "decode3"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 250
      has_bias: true
    }
  }

  #######
  # SELU selu8
  #######
  layer {
    parents: "decode3"
    name: "selu8"
    data_layout: "model_parallel"
    selu {
    }
  }

  #################
  # FULLY_CONNECTED decode2
  #################
  layer {
    parents: "selu8"
    name: "decode2"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 500
      has_bias: true
    }
  }

  #######
  # SELU selu9
  #######
  layer {
    parents: "decode2"
    name: "selu9"
    data_layout: "model_parallel"
    selu {
    }
  }

  #################
  # FULLY_CONNECTED decode1
  #################
  layer {
    parents: "selu9"
    name: "decode1"
    data_layout: "model_parallel"
    num_neurons_from_data_reader: true
    fully_connected {
      has_bias: true
    }
  }

  #######
  # SELU selu10
  #######
  layer {
    parents: "decode1"
    name: "selu10"
    data_layout: "model_parallel"
    #selu {
    sigmoid {
    }
  }


  #################
  # RECONSTRUCTION
  #################
  layer {
    parents: "relu10"
    name: "reconstruction"
    data_layout: "model_parallel"
    split {}
  }
  layer {
    parents: "reconstruction data"
    name: "mean_squared_error"
    data_layout: "model_parallel"
    mean_squared_error {}
  }

  #####################
  # PEARSON CORRELATION
  #####################
  # rho(x,y) = covariance(x,y) / sqrt( variance(x) * variance(y) )
  layer {
    parents: "reconstruction data"
    name: "pearson_r_cov"
    data_layout: "model_parallel"
    covariance {}
  }
  layer {
    parents: "data"
    name: "pearson_r_var1"
    data_layout: "model_parallel"
    variance {}
  }
  layer {
    parents: "reconstruction"
    name: "pearson_r_var2"
    data_layout: "model_parallel"
    variance {}
  }
  layer {
    parents: "pearson_r_var1 pearson_r_var2"
    name: "pearson_r_mult"
    data_layout: "model_parallel"
    multiply {}
  }
  layer {
    parents: "pearson_r_mult"
    name: "pearson_r_sqrt"
    data_layout: "model_parallel"
    sqrt {}
  }
  layer {
    parents: "pearson_r_cov pearson_r_sqrt"
    name: "pearson_r"
    data_layout: "model_parallel"
    divide {}
  }

  ###################################################
  # end of layers
  ###################################################
}
