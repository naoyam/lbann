trainer {
  block_size: 256
  procs_per_trainer: 0
  num_parallel_readers: 1
}
model {
  ### Model description and network architecture taken from:
  ### https://lc.llnl.gov/bitbucket/projects/BIOM/repos/molresp/browse/tf_model.py?at=TensorFlow_chemClass
  ### This network description is anologous to AutoEncoder_Chem_ECFP
  data_layout: "model_parallel"
  mini_batch_size: 128
  num_epochs: 4

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    layer_term { layer: "cross_entropy" }
    l2_weight_regularization {
      scale_factor: 1e-4
    }
  }

  ###################################################
  # Metrics
  ###################################################

  metric {
    layer_metric {
      name: "accuracy"
      layer: "categorical_accuracy"
    }
  }


  ###################################################
  # Callbacks
  ###################################################
  callback {
    print {
      interval: 1
    }
  }
  callback {
    timer {
    }
  }

  ###################################################
  # start of layers
  ###################################################

  #######
  # INPUT
  #######
  layer {
    name: "data"
    children: "finetunedata label"
    data_layout: "data_parallel"
    input {}
  }
  layer {
    parents: "data"
    name: "finetunedata"
    data_layout: "data_parallel"
    split {}
  }
  layer {
    parents: "data"
    name: "label"
    data_layout: "data_parallel"
    split {}
  }

  #################
  # FULLY_CONNECTED encode1
  #################
  layer {
    parents: "finetunedata"
    name: "encode1"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 2000
      has_bias: true
    }
  }

  ######
  # RELU relu1
  ######
  layer {
    parents: "encode1"
    name: "relu1"
    data_layout: "model_parallel"
    relu {
    }
  }

  #################
  # FULLY_CONNECTED encode2
  #################
  layer {
    parents: "relu1"
    name: "encode2"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 1000
      has_bias: true
    }
  }

  #######
  # RELU relu2
  #######
  layer {
    parents: "encode2"
    name: "relu2"
    data_layout: "model_parallel"
    relu {
    }
  }

  #################
  # FULLY_CONNECTED encode3
  #################
  layer {
    parents: "relu2"
    name: "encode3"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 500
      has_bias: true
    }
  }

  #######
  # RELU relu3
  #######
  layer {
    parents: "encode3"
    name: "relu3"
    data_layout: "model_parallel"
    relu {
    }
  }

  #################
  # FULLY_CONNECTED encode4
  #################
  layer {
    parents: "relu3"
    name: "encode4"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 250
      has_bias: true
    }
  }

  #######
  # RELU relu4
  #######
  layer {
    parents: "encode4"
    name: "relu4"
    data_layout: "model_parallel"
    relu {
    }
  }

  #################
  # FULLY_CONNECTED encode5
  #################
  layer {
    parents: "relu4"
    name: "encode5"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 100
      has_bias: true
    }
  }

  #######
  # RELU relu5
  #######
  layer {
    parents: "encode5"
    name: "relu5"
    data_layout: "model_parallel"
    relu {
    }
  }


  layer {
    parents: "relu5"
    name: "ip2"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 2
      has_bias: true
    }
  }

  layer {
    parents: "ip2"
    name: "prob"
    data_layout: "model_parallel"
    softmax {}
  }

  layer {
    parents: "prob label"
    name: "cross_entropy"
    data_layout: "model_parallel"
    cross_entropy {}
  }

  layer {
    parents: "prob label"
    name: "categorical_accuracy"
    data_layout: "model_parallel"
    categorical_accuracy {}
  }

  ###################################################
  # end of layers
  ###################################################
}
