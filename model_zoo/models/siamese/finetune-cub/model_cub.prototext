trainer {
  block_size: 256
  procs_per_trainer: 0
  num_parallel_readers: 0
}
model {
  data_layout: "data_parallel"
  mini_batch_size: 64
  num_epochs: 50

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    layer_term { layer: "cross_entropy_new" }
    l2_weight_regularization {
      scale_factor: 0.0005
    }
  }

  ###################################################
  # Metrics
  ###################################################

  metric {
    layer_metric {
      name: "categorical accuracy"
      layer: "top1_accuracy_new"
      unit: "%"
    }
  }
  metric {
    layer_metric {
      name: "top-5 categorical accuracy"
      layer: "top5_accuracy_new"
      unit: "%"
    }
  }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    imcomm {
      intertrainer_comm_method: "normal"
      all_optimizers: true
    }
  }
  callback { print {} }
  callback { timer {} }
  callback {
    poly_learning_rate {
      power: 0.5
    }
  }

  ###################################################
  # start of weights
  ###################################################

  # The weights of the layers conv1_head0, conv2_head0, conv3_head0, conv4_head0, and conv5_head0
  # will be initialized as described here but overwritten with pretrained ones.
  # The optimizer states may not be transferred if lbann2 is used.
  # The weights of the rest learning layers will be initialized as described here and trained fresh.

  weights {
    name: "conv1_kernel"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.01
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv1_bias"
    initializer {
      constant_initializer {
        value: 0.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv2_kernel"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.01
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv2_bias"
    initializer {
      constant_initializer {
        value: 1.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv3_kernel"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.01
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv3_bias"
    initializer {
      constant_initializer {
        value: 0.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv4_kernel"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.01
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv4_bias"
    initializer {
      constant_initializer {
        value: 1.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "conv5_kernel"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.01
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "conv5_bias"
    initializer {
      constant_initializer {
        value: 1.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc6_new_linearity"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.005
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc6_new_bias"
    initializer {
      constant_initializer {
        value: 1.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc7_new_linearity"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.005
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc7_new_bias"
    initializer {
      constant_initializer {
        value: 1.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  weights {
    name: "fc8_new_linearity"
    initializer {
      normal_initializer {
        mean: 0.0
        standard_deviation: 0.01
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.01
        momentum: 0.9
        decay_rate: 0.0002
        nesterov: false
      }
    }
  }

  weights {
    name: "fc8_new_bias"
    initializer {
      constant_initializer {
        value: 0.0
      }
    }
    optimizer {
      sgd {
        learn_rate: 0.02
        momentum: 0.9
        decay_rate: 0
        nesterov: false
      }
    }
  }

  ###################################################
  # start of replicate layers
  ###################################################

  layer {
    name: "input_new"
    children: "data_new label_new"
    data_layout: "data_parallel"
    input {
    }
  }
  layer {
    parents: "input_new"
    name: "data_new"
    data_layout: "data_parallel"
    split {}
  }
  layer {
    parents: "input_new"
    name: "label_new"
    data_layout: "data_parallel"
    split {}
  }

  layer {
    parents: "data_new"
    name: "conv1_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 96
      conv_dims: "11 11"
      conv_pads: "5 5"
      conv_strides: "4 4"
      has_bias: true
      has_vectors: true
    }
    weights: "conv1_kernel conv1_bias"
  }

  layer {
    parents: "conv1_head0"
    name: "relu1_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu1_new"
    name: "pool1_new"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool1_new"
    name: "norm1_new"
    data_layout: "data_parallel"
    local_response_normalization {
      window_width: 5
      lrn_alpha: 0.0001
      lrn_beta: 0.75
      lrn_k: 2
    }
  }

  layer {
    parents: "norm1_new"
    name: "conv2_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels: 256
      conv_dims: "5 5"
      conv_pads: "2 2"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv2_kernel conv2_bias"
  }

  layer {
    parents: "conv2_head0"
    name: "relu2_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu2_new"
    name: "pool2_new"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  layer {
    parents: "pool2_new"
    name: "norm2_new"
    data_layout: "data_parallel"
    local_response_normalization {
      window_width: 5
      lrn_alpha: 0.0001
      lrn_beta: 0.75
      lrn_k: 2
    }
  }

  layer {
    parents: "norm2_new"
    name: "conv3_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv3_kernel conv3_bias"
  }

  layer {
    parents: "conv3_head0"
    name: "relu3_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu3_new"
    name: "conv4_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  384
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv4_kernel conv4_bias"
  }

  layer {
    parents: "conv4_head0"
    name: "relu4_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu4_new"
    name: "conv5_head0"
    data_layout: "data_parallel"
    convolution {
      num_dims: 2
      num_output_channels:  256
      conv_dims: "3 3"
      conv_pads: "1 1"
      conv_strides: "1 1"
      has_bias: true
      has_vectors: true
    }
    weights: "conv5_kernel conv5_bias"

    # Control whether to freeze the pre-trained layers of this sequential model:
    # conv1_head0, conv2_head0, conv3_head0, conv4_head0, and conv5_head0.
    # Setting true for a sequential model freezes the current layer as well as those precedes.
    freeze: false
  }

  layer {
    parents: "conv5_head0"
    name: "relu5_new"
    data_layout: "data_parallel"
    relu {}
  }

  layer {
    parents: "relu5_new"
    name: "pool5_new"
    data_layout: "data_parallel"
    pooling {
      num_dims: 2
      pool_dims: "3 3"
      pool_pads: "0 0"
      pool_strides: "2 2"
      pool_mode: "max"
      has_vectors: true
    }
  }

  ###################################################
  # end of replicate layers
  ###################################################

  layer {
    parents: "pool5_new"
    name: "fc6_new"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc6_new_linearity fc6_new_bias"
  }

  layer {
    parents: "fc6_new"
    name: "relu6_new"
    data_layout: "model_parallel"
    relu {}
  }

  layer {
    parents: "relu6_new"
    name: "drop6_new"
    data_layout: "model_parallel"
    dropout {
      keep_prob: 0.9
    }
  }

  layer {
    parents: "drop6_new"
    name: "fc7_new"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 4096
      has_bias: true
    }
    weights: "fc7_new_linearity fc7_new_bias"
  }

  layer {
    parents: "fc7_new"
    name: "relu7_new"
    data_layout: "model_parallel"
    relu {}
  }

  layer {
    parents: "relu7_new"
    name: "drop7_new"
    data_layout: "model_parallel"
    dropout {
      keep_prob: 0.9
    }
  }

  layer {
    parents: "drop7_new"
    name: "fc8_new"
    data_layout: "model_parallel"
    # The number of outputs specific to the dataset used.
    # E.g., 200 for CUB, and 431 for CompCars.
    hint_layer: "label_new"
    fully_connected {
      has_bias: false
    }
    weights: "fc8_new_linearity fc8_new_bias"
  }

  layer {
    parents: "fc8_new"
    name: "prob_new"
    data_layout: "model_parallel"
    softmax {}
  }

  layer {
    parents: "prob_new label_new"
    name: "cross_entropy_new"
    data_layout: "data_parallel"
    cross_entropy {}
  }
  layer {
    parents: "prob_new label_new"
    name: "top1_accuracy_new"
    data_layout: "data_parallel"
    categorical_accuracy {}
  }
  layer {
    parents: "prob_new label_new"
    name: "top5_accuracy_new"
    data_layout: "data_parallel"
    top_k_categorical_accuracy { k: 5 }
  }

}
