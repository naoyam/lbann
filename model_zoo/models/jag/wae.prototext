trainer {
  block_size: 256
  procs_per_trainer:0
}
model {
  random_init_models_differently: true
  serialize_io: true
  objective_function {
    l2_weight_regularization {
      scale_factor: 0.0001
    }
    layer_term {
      scale_factor: 1.0
      #layer: "disc1_real_eval"
      layer: "disc1_real_bce"
    }
    layer_term {
      scale_factor: 1.0
      #layer: "disc1_fake_eval"
      layer: "disc1_fake_bce"
    }
    layer_term {
      #lam = 0.01
      scale_factor: 0.01
      layer: "g_adv1_bce"
    }
    layer_term {
      scale_factor: 1.0
      layer: "img_loss"
    }
    layer_term {
      scale_factor: 1.0
      layer: "rec_error"
    }
  }
  metric {
    layer_metric {
      layer: "img_loss"
    }
  }
  num_epochs: 100
  data_layout: "data_parallel"
  layer {
    input {
      data_set_per_model: true
      target_mode: "N/A"
    }
    name: "data1"
    data_layout: "data_parallel"
  }
  #z or sample_z
  #@todo z = -1+2*np.random.rand(batch_size, zdim=20)
  layer {
    name: "sample_z"
    data_layout: "data_parallel"
    gaussian {
      mean: 0.0
      stdev: 1.0
      neuron_dims: "20"
    }
  }

  layer {
    name: "zero"
    data_layout: "data_parallel"
    constant {
      value: 0.0
      num_neurons: "1"
    }
  }
  layer {
    name: "one"
    data_layout: "data_parallel"
    constant {
      value: 1.0
      num_neurons: "1"
    }
  }

  layer {
    name: "slice_data"
    data_layout: "data_parallel"
    parents: "data1"
    children: "image_data_dummy param_data_id"
    slice {
      get_slice_points_from_reader: "independent"
    }
  }
  layer {
    identity {
    }
    name: "image_data_dummy"
    data_layout: "data_parallel"
    parents: "slice_data"
  }
  layer {
    identity {
    }
    name: "param_data_id"
    data_layout: "data_parallel"
    parents: "slice_data"
  }

  #concate image data with sample_z
  layer {
    name: "concat_y_n_samplez"
    data_layout: "data_parallel"
    parents: "image_data_dummy sample_z"
    concatenation {
    }
  }

  ###generator == encoder
  layer {
    fully_connected {
      num_neurons: 32
      has_bias: true
    }
    name: "gen1fc1"
    data_layout: "data_parallel"
    #weights: "gen1fc1linearity"
    parents: "image_data_dummy"
  }
  layer {
    elu {
    }
    name: "gen1relu1"
    data_layout: "data_parallel"
    parents: "gen1fc1"
  }
  layer {
    fully_connected {
      num_neurons: 256
      has_bias: true
    }
    name: "gen1fc2"
    data_layout: "data_parallel"
    #weights: "gen1fc2linearity"
    parents: "gen1relu1"
  }
  layer {
    tanh {
    }
    name: "gen1relu2"
    data_layout: "data_parallel"
    parents: "gen1fc2"
  }
  layer {
    dropout {
      keep_prob: 1.0
    }
    name: "gen1dropout1"
    data_layout: "data_parallel"
    parents: "gen1relu2"
  }
  layer {
    fully_connected {
      num_neurons: 128
      has_bias: true
    }
    name: "gen1fc3"
    data_layout: "data_parallel"
    #weights: "gen1fc3linearity"
    parents: "gen1dropout1"
  }
  layer {
    tanh {
    }
    name: "gen1relu3"
    data_layout: "data_parallel"
    parents: "gen1fc3"
  }
  layer {
    fully_connected {
      #gen output is latent dim
      num_neurons: 20
      has_bias: true
    }
    #z_sample
    name: "gen1fc4"
    data_layout: "data_parallel"
    #weights: "gen1fc4linearity"
    parents: "gen1relu3"
  }

  ####Discriminator
  layer {
    fully_connected {
      num_neurons: 128
      has_bias: true
    }
    name: "d1fc1_real"
    data_layout: "data_parallel"
    weights: "d1fc1linearity d1fc1bias"
    parents: "concat_y_n_samplez"
  }
  layer {
    elu {
    }
    #@todo: use "acts" for activation instead of actualy type
    name: "d1relu1_real"
    data_layout: "data_parallel"
    parents: "d1fc1_real"
  }
  layer {
    fully_connected {
      num_neurons: 64
      has_bias: true
    }
    name: "d1fc2_real"
    data_layout: "data_parallel"
    weights: "d1fc2linearity d1fc2bias"
    parents: "d1relu1_real"
  }
  layer {
    tanh {
    }
    name: "d1relu2_real"
    data_layout: "data_parallel"
    parents: "d1fc2_real"
  }
  layer {
    fully_connected {
      num_neurons: 1
      has_bias: true
    }
    ## This is D_prior
    name: "d1fc3_real"
    data_layout: "data_parallel"
    weights: "d1fc3linearity d1fc3bias"
    parents: "d1relu2_real"
  }
  layer {
    name: "concat_y_n_zsample"
    data_layout: "data_parallel"
    parents: "image_data_dummy gen1fc4"
    children: "d1_stop_gradient d2_dummy"
    concatenation {
    }
  }
  layer {
    name: "d1_stop_gradient"
    data_layout: "data_parallel"
    parents: "concat_y_n_zsample"
    stop_gradient {
    }
  }
  layer {
    fully_connected {
      num_neurons: 128
      has_bias: true
    }
    name: "d1fc1_fake"
    data_layout: "data_parallel"
    weights: "d1fc1linearity d1fc1bias"
    parents: "d1_stop_gradient"
  }
  layer {
    elu {
    }
    name: "d1relu1_fake"
    data_layout: "data_parallel"
    parents: "d1fc1_fake"
  }
  layer {
    fully_connected {
      num_neurons: 64
      has_bias: true
    }
    name: "d1fc2_fake"
    data_layout: "data_parallel"
    weights: "d1fc2linearity d1fc2bias"
    parents: "d1relu1_fake"
  }
  layer {
    tanh {
    }
    name: "d1relu2_fake"
    data_layout: "data_parallel"
    parents: "d1fc2_fake"
  }
  layer {
    fully_connected {
      num_neurons: 1
      has_bias: true
    }
    #This is D_sample
    name: "d1fc3_fake"
    data_layout: "data_parallel"
    weights: "d1fc3linearity d1fc3bias"
    parents: "d1relu2_fake"
  }
  layer {
    sigmoid_binary_cross_entropy {
    }
    name: "disc1_real_bce"
    data_layout: "data_parallel"
    parents: "d1fc3_real one"
  }
  layer {
    sigmoid_binary_cross_entropy {
    }
    name: "disc1_fake_bce"
    data_layout: "data_parallel"
    parents: "d1fc3_fake zero"
  }
  layer {
    identity {
    }
    name: "d2_dummy"
    data_layout: "data_parallel"
    parents: "concat_y_n_zsample"
  }
  layer {
    freeze: true
    fully_connected {
      num_neurons: 128
      has_bias: true
    }
    name: "d2fc1"
    data_layout: "data_parallel"
    parents: "d2_dummy"
  }
  layer {
    elu {
    }
    name: "d2relu1"
    data_layout: "data_parallel"
    parents: "d2fc1"
  }
  layer {
    freeze: true
    fully_connected {
      num_neurons: 64
      has_bias: true
    }
    name: "d2fc2"
    data_layout: "data_parallel"
    parents: "d2relu1"
  }
  layer {
    tanh {
    }
    name: "d2relu2"
    data_layout: "data_parallel"
    parents: "d2fc2"
  }
  layer {
    freeze: true
    fully_connected {
      num_neurons: 1
      has_bias: true
    }
    name: "d2fc3"
    data_layout: "data_parallel"
    parents: "d2relu2"
  }
  layer {
    sigmoid_binary_cross_entropy {
    }
    name: "g_adv1_bce"
    data_layout: "data_parallel"
    parents: "d2fc3 one"
  }
  layer {
    name: "decode0_minus_y"
    data_layout: "data_parallel"
    parents: "decode0 image_data_dummy"
   weighted_sum {
      scaling_factors: "1 -1"
    }
  }
  #L2loss
  layer {
    l2_norm2 {
    }
    name: "rec_error"
    data_layout: "data_parallel"
    parents: "decode0_minus_y"
  }

  layer {
    parents: "decode0 image_data_dummy"
    name: "img_loss"
    data_layout: "data_parallel"
    mean_squared_error {}
  }


  ######################
  # Decoder
  ######################

  # decode3
  layer {
    parents: "gen1fc4"
    name: "decode3"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 64
      has_bias: true
    }
  }
  layer {
    parents: "decode3"
    name: "decode3_tanh"
    data_layout: "data_parallel"
    elu {}
  }
  layer {
    parents: "decode3_tanh"
    name: "decode3_dropout"
    data_layout: "data_parallel"
    dropout {
      keep_prob: 1.0
    }
  }

  # decode2
  layer {
    parents: "decode3_dropout"
    name: "decode2"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 128
      has_bias: true
    }
  }
  layer {
    parents: "decode2"
    name: "decode2_tanh"
    data_layout: "data_parallel"
    tanh {}
  }
  layer {
    parents: "decode2_tanh"
    name: "decode2_dropout"
    data_layout: "data_parallel"
    dropout {
      keep_prob: 1.0
    }
  }

  # decode1
  layer {
    parents: "decode2_dropout"
    name: "decode1"
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 256
      has_bias: true
    }
  }
  layer {
    parents: "decode1"
    name: "decode1_elu"
    data_layout: "data_parallel"
    tanh {
    }
  }
  layer {
    parents: "decode1_elu"
    name: "decode1_dropout"
    data_layout: "data_parallel"
    dropout {
      keep_prob: 1.0
    }
  }

  # decode0
  layer {
    parents: "decode1_dropout"
    name: "decode0"
    data_layout: "data_parallel"
    hint_layer: "image_data_dummy"
    fully_connected {
      has_bias: true
    }
  }

  ######################

  weights {
    name: "gen1fc1linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "gen1fc2linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "gen1fc3linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "gen1fc4linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "d1fc1linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "d1fc1bias"
  }
  weights {
    name: "d1fc2linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "d1fc2bias"
  }
  weights {
    name: "d1fc3linearity"
    initializer {
      he_normal_initializer {
      }
    }
  }
  weights {
    name: "d1fc3bias"
  }
  mini_batch_size: 64
  callback {
    print {
      interval: 1
    }
  }
  callback {
    timer {
    }
  }
  callback {
    replace_weights {
      source_layers: "d1fc1_real d1fc2_real d1fc3_real"
      destination_layers: "d2fc1 d2fc2 d2fc3"
      batch_interval: 2
    }
  }
  #callback {
  #  dump_outputs {
  #    prefix: "/dir/to/save/imgs"
  #    batch_interval: 10
  #    layers: "gen1fc4"
  #    execution_modes: "test"
  #  }
  #}
  #callback {
  #  ltfb {
  #    batch_interval: 100
  #    low_score_wins: true
  #    metric: "l_l2_y_eval"
  #    #weights_tosend: "gen1fc1linearity gen1fc1bias gen1fc2linearity gen1fc2bias gen1fc3linearity gen1fc3bias gen1fc4linearity gen1fc4bias"
  #    weights: "gen1fc1_linearity_weights gen1fc1_bias_weights gen1fc2_linearity_weights gen1fc2_bias_weights gen1fc3_linearity_weights gen1fc3_bias_weights gen1fc4_linearity_weights gen1fc4_bias_weights"
  #    }

 # }
}
